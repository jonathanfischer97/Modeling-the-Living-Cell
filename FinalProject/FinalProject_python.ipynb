{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mTraceback (most recent call last):\n",
      "\u001b[1;31m  File \"/Users/jonathanfischer/.vscode/extensions/ms-toolsai.jupyter-2022.11.1003412109/pythonFiles/vscode_datascience_helpers/jupyter_daemon.py\", line 158, in _start_notebook\n",
      "\u001b[1;31m    from notebook import notebookapp as app\n",
      "\u001b[1;31m  File \"/Users/jonathanfischer/miniforge3/envs/m1/lib/python3.9/site-packages/notebook/notebookapp.py\", line 59, in <module>\n",
      "\u001b[1;31m    from tornado import httpserver\n",
      "\u001b[1;31m  File \"/Users/jonathanfischer/miniforge3/envs/m1/lib/python3.9/site-packages/tornado/httpserver.py\", line 29, in <module>\n",
      "\u001b[1;31m    import ssl\n",
      "\u001b[1;31m  File \"/Users/jonathanfischer/miniforge3/envs/m1/lib/python3.9/ssl.py\", line 99, in <module>\n",
      "\u001b[1;31m    import _ssl             # if we can't import it, let the error propagate\n",
      "\u001b[1;31mImportError: dlopen(/Users/jonathanfischer/miniforge3/envs/m1/lib/python3.9/lib-dynload/_ssl.cpython-39-darwin.so, 0x0002): Library not loaded: @rpath/libssl.1.1.dylib\n",
      "\u001b[1;31m  Referenced from: <AFC2AED8-3B6E-30C6-8138-6BB9C183B98B> /Users/jonathanfischer/miniforge3/envs/m1/lib/python3.9/lib-dynload/_ssl.cpython-39-darwin.so\n",
      "\u001b[1;31m  Reason: tried: '/Users/jonathanfischer/miniforge3/envs/m1/lib/python3.9/lib-dynload/../../libssl.1.1.dylib' (mach-o file, but is an incompatible architecture (have 'x86_64', need 'arm64')), '/Users/jonathanfischer/miniforge3/envs/m1/lib/python3.9/lib-dynload/../../libssl.1.1.dylib' (mach-o file, but is an incompatible architecture (have 'x86_64', need 'arm64')), '/Users/jonathanfischer/miniforge3/envs/m1/bin/../lib/libssl.1.1.dylib' (mach-o file, but is an incompatible architecture (have 'x86_64', need 'arm64')), '/Users/jonathanfischer/miniforge3/envs/m1/bin/../lib/libssl.1.1.dylib' (mach-o file, but is an incompatible architecture (have 'x86_64', need 'arm64')), '/System/Volumes/Preboot/Cryptexes/OS@rpath/libssl.1.1.dylib' (no such file), '/Users/jonathanfischer/miniforge3/envs/m1/lib/python3.9/lib-dynload/../../libssl.1.1.dylib' (mach-o file, but is an incompatible architecture (have 'x86_64', need 'arm64')), '/Users/jonathanfischer/miniforge3/envs/m1/lib/python3.9/lib-dynload/../../libssl.1.1.dylib' (mach-o file, but is an incompatible architecture (have 'x86_64', need 'arm64')), '/Users/jonathanfischer/miniforge3/envs/m1/bin/../lib/libssl.1.1.dylib' (mach-o file, but is an incompatible architecture (have 'x86_64', need 'arm64')), '/Users/jonathanfischer/miniforge3/envs/m1/bin/../lib/libssl.1.1.dylib' (mach-o file, but is an incompatible architecture (have 'x86_64', need 'arm64')), '/usr/local/lib/libssl.1.1.dylib' (no such file), '/usr/lib/libssl.1.1.dylib' (no such file, not in dyld cache)\n",
      "\u001b[1;31m\n",
      "\u001b[1;31mDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31m\n",
      "\u001b[1;31mTraceback (most recent call last):\n",
      "\u001b[1;31m  File \"/Users/jonathanfischer/.vscode/extensions/ms-toolsai.jupyter-2022.11.1003412109/pythonFiles/vscode_datascience_helpers/daemon/daemon_python.py\", line 54, in _decorator\n",
      "\u001b[1;31m    return func(self, *args, **kwargs)\n",
      "\u001b[1;31m  File \"/Users/jonathanfischer/.vscode/extensions/ms-toolsai.jupyter-2022.11.1003412109/pythonFiles/vscode_datascience_helpers/jupyter_daemon.py\", line 111, in m_exec_module_observable\n",
      "\u001b[1;31m    self._start_notebook(args, cwd, env)\n",
      "\u001b[1;31m  File \"/Users/jonathanfischer/.vscode/extensions/ms-toolsai.jupyter-2022.11.1003412109/pythonFiles/vscode_datascience_helpers/jupyter_daemon.py\", line 160, in _start_notebook\n",
      "\u001b[1;31m    from notebook import app as app\n",
      "\u001b[1;31mImportError: cannot import name 'app' from 'notebook' (/Users/jonathanfischer/miniforge3/envs/m1/lib/python3.9/site-packages/notebook/__init__.py)\n",
      "\u001b[1;31m\n",
      "\u001b[1;31mFailed to run jupyter as observable with args notebook --no-browser --notebook-dir=\"/Users/jonathanfischer/Desktop/Modeling the Living Cell/FinalProject\" --config=/var/folders/p7/6p67sy_d4c9b31d7spz9z9kw0000gn/T/8252aeb5-cdfd-48f0-ac30-3430bd681e24/jupyter_notebook_config.py --NotebookApp.iopub_data_rate_limit=10000000000.0. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import math\n",
    "import peakutils\n",
    "import numpy.fft as fft\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker \n",
    "from scipy.integrate import odeint \n",
    "import scipy.signal as signal \n",
    "from scipy.spatial import KDTree\n",
    "\n",
    "\n",
    "import pickle \n",
    "from numpy import random\n",
    "from deap import creator, base, tools, algorithms \n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans  \n",
    "import os \n",
    "import os.path \n",
    "\n",
    "from SALib.sample import saltelli, fast_sampler, latin\n",
    "from SALib.sample.morris import sample\n",
    "from SALib.analyze import sobol, fast, morris, delta\n",
    "from SALib.plotting.morris import horizontal_bar_plot, covariance_plot, sample_histograms\n",
    "\n",
    "import glob \n",
    "from pathlib import Path\n",
    "import shutil\n",
    "from numba import njit, typed\n",
    "import subprocess\n",
    "import stat\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The deterministic model of biological oscillator\n",
    "''' \n",
    "#@experimental.jitclass\n",
    "class Oscillator: \n",
    "\tdef __init__(self, parameter_values, params, initial_conditions, dt = 0.1, mode = 1, sigma = 0.001, volume = 0.5): \n",
    "\t\tself.nParams = len(params)   \n",
    "\t\tself.params = params #model parameters\n",
    "\t\tself.parameter_values = parameter_values #allowed parameter ranges  \n",
    "\t\tself.y0 = initial_conditions \n",
    "\t\tself.volume = volume\n",
    "\t\tself.copynumbers = [self.copynumber(x) for x in self.y0]\t\n",
    "\t\tself.dt = dt\n",
    "\t\tself.sigma = sigma\n",
    "\t\tself.T = 20 \n",
    "\t\tself.N = int(self.T/self.dt) \n",
    "\t\tself.ts = np.linspace(0, self.T, self.N) \n",
    "\t\tself.amp = 300 #[nM] \t\t\n",
    "\t\tself.per = self.T/8 \t\n",
    "\t\tself.sample_rate \t\t= 0.0033333333 #Hz \n",
    "\t\tself.samples_per_hour \t= (1/self.dt)\t\t\n",
    "\t\tself.jump \t\t\t\t= int(self.samples_per_hour/(self.sample_rate*3600)) if int(self.samples_per_hour/(self.sample_rate*3600)) else 1 \t \t\n",
    "\t\tself.ideal = self.amp*(np.sin(math.pi*(self.ts)/self.per - math.pi/2) + 1) \n",
    "\t\t#number of samples for FFT\t\t\n",
    "\t\tself.nS = self.N/self.jump \n",
    "\t\tself.dF = self.sample_rate/self.nS  \n",
    "\t\tself.idealF = self.getFrequencies(self.ideal) \n",
    "\t\tself.idealFreq = 0.3 #peaks per second \t\n",
    "\t\tself.penalty = 0.5 \t\n",
    "\t\tthresholdOne = -(self.nS/2)*100 #10nM -+ from ideal signal harmonics       \n",
    "\t\tthresholdTwo = 0.1\n",
    "\t\tthresholdThree = 0.1\n",
    "\t\t#self.maxFreq = 0.5\n",
    "\t\t#self.maxPeaks = self.maxFreq * self.T  \n",
    "\t\tself.minAmp = 1\n",
    "\t\tself.maxAmp = 6000 \n",
    "\t\tself.mode = mode    \t\t\t\n",
    "\t\tself.modes = [self.eval]       \n",
    "\t\tself.threshold = thresholdOne  \n",
    "\t\tself.omega = 1000 #nm^-1 \n",
    "\t\tif self.mode == 1:\n",
    "\t\t\tself.threshold = thresholdTwo\n",
    "\t\telif self.mode == 2:\n",
    "\t\t\tself.threshold = thresholdThree\n",
    "\t\n",
    "\t#gets summed difference of arrayData\n",
    "\t@staticmethod \t\n",
    "\tdef getDif(indexes, arrayData):\t\n",
    "\t\tarrLen = len(indexes)\n",
    "\t\tsum = 0\n",
    "\t\tfor i, ind in enumerate(indexes):\n",
    "\t\t\tif i == arrLen - 1:\n",
    "\t\t\t\tbreak\n",
    "\t\t\tsum += arrayData[ind] - arrayData[indexes[i + 1]]\n",
    "\t\t\t\n",
    "\t\t#add last peak - same as substracting it from zero \n",
    "\t\tsum += arrayData[indexes[-1:]]  \n",
    "\t\treturn sum   \n",
    "\t\t\n",
    "\t#gets standard deviation \n",
    "\t@staticmethod \n",
    "\tdef getSTD(indexes, arrayData, window):\n",
    "\t\tnumPeaks = len(indexes)\n",
    "\t\tarrLen = len(arrayData)\n",
    "\t\tsum = 0\n",
    "\t\tfor ind in indexes:\n",
    "\t\t\tminInd = max(0, ind - window)\n",
    "\t\t\tmaxInd = min(arrLen, ind + window)\n",
    "\t\t\tsum += np.std(arrayData[minInd:maxInd])  \n",
    "\t\t\t\n",
    "\t\tsum = sum/numPeaks \t\n",
    "\t\treturn sum\t \n",
    "\t\n",
    "\tdef getFrequencies(self, y):\n",
    "\t\t#fft sample rate: 1 sample per 5 minutes\n",
    "\t\ty = y[0::self.jump]  \n",
    "\t\tres = abs(fft.rfft(y))\n",
    "\t\t#normalize the amplitudes \n",
    "\t\tres = res/math.ceil(self.nS/2) \n",
    "\t\treturn res\n",
    "\n",
    "\tdef costOne(self, Y): \n",
    "\t\tp1 = Y[:,1]   \n",
    "\t\tfftData = self.getFrequencies(p1)     \n",
    "\t\t\n",
    "\t\tdiff = fftData - self.idealF         \n",
    "\t\tcost = -np.dot(diff, diff) \t\t\n",
    "\t\treturn cost,\t\n",
    "\t\t\n",
    "\tdef costTwo(self, Y, getAmplitude = False): \n",
    "\t\tp1 = Y[:,-1] \n",
    "\t\tfftData = self.getFrequencies(p1)      \n",
    "\t\tfftData = np.array(fftData) \n",
    "\t\t\n",
    "\t\t#find peaks using very low threshold and minimum distance\n",
    "\t\t#indexes = peakutils.indexes(fftData, thres=0.02/max(fftData), min_dist=1) \n",
    "\t\t#find number of peaks in time domain for frequency threshold\n",
    "\t\t#peaknumber = len(peakutils.indexes(p1, thres=0.02/max(fftData), min_dist=1))  \n",
    "\n",
    "\t\tindexes = peakutils.indexes(fftData, thres=np.mean(fftData), min_dist=10, thres_abs = True) \n",
    "\t\t#find number of peaks in time domain for frequency threshold\n",
    "\t\tpeaknumber = len(peakutils.indexes(p1, thres=np.mean(p1), min_dist=1, thres_abs = True)) \n",
    "\n",
    "\t\t#in case of no oscillations return 0 \n",
    "\t\tif len(indexes) == 0 or peaknumber == 0:\n",
    "\t\t\treturn 0 , 0 \n",
    "\t\t#if amplitude is greater than 400nM\n",
    "\t\tamp = np.max(fftData[indexes])\n",
    "\t\tif amp > self.maxAmp: \n",
    "\t\t\treturn 0 ,0 \n",
    "\t\tfitSamples = fftData[indexes]  \t\t\t\n",
    "\t\tstd = self.getSTD(indexes, fftData, 1)  \n",
    "\t\tdiff = self.getDif(indexes, fftData)  \n",
    "\t\tpenalty =  ((abs(self.idealFreq - (peaknumber/self.T)))*self.penalty)\n",
    "\t\tcost = std + diff #- penalty #penalize difference from ideal frequency\n",
    "\t\t#print(cost)   \n",
    "\t\tif getAmplitude:\n",
    "\t\t\treturn cost, amp\n",
    "\t\treturn cost#, penalty\n",
    "\n",
    "\tdef costYield(self, Y): #optimize for yield of trimer \n",
    "\t\tif max(Y[:,-1]) < sum(self.y0):\n",
    "\t\t\treturn Y[1:round(len(Y[:,-1])/2),-1], 0 #return mid\n",
    "\t\telse:\n",
    "\t\t\treturn Y[1,1], 0\n",
    "\t\t\n",
    "\tdef isViableFitness(self, fit):\n",
    "\t\treturn fit >= self.threshold\n",
    "\t\t\n",
    "\tdef isViable(self, point): \n",
    "\t\tfitness = self.eval(point)  \n",
    "\t\t# if self.mode == 0:\n",
    "\t\t# \treturn self.isViableFitness(fitness[0]) \n",
    "\t\t\t\n",
    "\t\tfit = fitness[0]\n",
    "\n",
    "\t\t# amp = 0\n",
    "\t\t# if fit > 0:\n",
    "\t\t# \tamp = fitness[1] \n",
    "\t\treturn self.isViableFitness(fit) #and amp >= self.minAmp and amp <= self.maxAmp   \n",
    "\n",
    "\n",
    "\t\t\n",
    "\t#evaluates a candidate  \n",
    "\tdef eval(self, candidate, getAmplitude = True): \n",
    "\t\tY = np.array(self.simulate(candidate)) \n",
    "\t\tif self.mode == 0:\n",
    "\t\t\treturn self.costOne(Y)  \n",
    "\t\telif self.mode == 1:\n",
    "\t\t\treturn self.costTwo(Y, getAmplitude)   #False before 7-26  \n",
    "\t\telse:\n",
    "\t\t\treturn self.costYield(Y)\n",
    "\n",
    "\t\n",
    "\t#simulates a candidate\n",
    "\tdef simulate(self, candidate):\n",
    "\t\t# y0 =  [candidate[0],candidate[1],candidate[2],candidate[3],0,candidate[4],0,0,0,0,0,0]\n",
    "\t\treturn odeint(self.oscillatorModelOde, self.y0, self.ts, args=(typed.List(candidate),))   \t\n",
    "\n",
    "\t\t\n",
    "\n",
    "\tdef plotModel(self, subject, mode=\"ode\", lipid = True, show=True):     \t\t\n",
    "\t\tif mode == \"ode\":\n",
    "\t\t\tt = np.linspace(0, self.T, self.N)\n",
    "\t\t\tsolutions = self.simulate(subject) \t\t\t\n",
    "\t\telse:\n",
    "\t\t\t#ssa simulation\n",
    "\t\t\t# can = self.full_converter(subject, True)\n",
    "\t\t\tt,solutions = self.ssa(subject)\n",
    "\t\t\t\n",
    "\t\tfig = plt.figure(figsize=(8,4),dpi=200)\n",
    "\n",
    "\t\tif lipid == True:\n",
    "\t\t\tplt.plot(t,solutions[:,0], color=\"b\", label = 'PIP')\n",
    "\t\t\tplt.plot(t,solutions[:,1], color=\"orange\", label = 'PIP2')\n",
    "\t\t\t#plt.plot(t,solutions[:,2], color=\"gold\", label = 'K')\n",
    "\t\t\t#plt.plot(t,solutions[:,3], color=\"r\", label = 'P')\n",
    "\t\t\t#plt.plot(t,solutions[:,4], color=\"cyan\", label = 'LK')\n",
    "\t\t\tplt.plot(t,solutions[:,5], color=\"r\", label = 'AP2')\n",
    "\t\t\t# plt.plot(t,solutions[:,6], color=\"g\", label = 'PIP2-AP2')\n",
    "\t\t\t#plt.plot(t,solutions[:,7], color=\"yellow\", label = 'LpAK')\n",
    "\t\t\t#plt.plot(t,solutions[:,8], color=\"magenta\", label = 'LpAP')\n",
    "\t\t\t#plt.plot(t,solutions[:,9], color=\"deeppink\", label = 'LpAPLp')\n",
    "\t\t\t#plt.plot(t,solutions[:,10], color=\"peru\", label = 'LpAKL')\n",
    "\t\t\t#plt.plot(t,solutions[:,11], color=\"purple\", label = 'LpP')\n",
    "\t\t\t# plt.plot(t,solutions[:,13], color = \"cyan\", label = 'PIP2-AP2-TfR')\n",
    "\t\t\t# plt.plot(t,solutions[:,-3], color = \"violet\", label = 'XBCD')\n",
    "\t\telse:\n",
    "\t\t\tplt.plot(t,solutions[:,-6], color = \"deeppink\", label = 'X')\n",
    "\n",
    "\t\t\tplt.plot(t,solutions[:,-11], color = \"purple\", label = 'XA')\n",
    "\n",
    "\t\t\tplt.plot(t,solutions[:,-5], color = \"plum\", label = 'XAB')\n",
    "\t\t\tplt.plot(t,solutions[:,-4], color = \"magenta\", label = 'XXAB')\n",
    "\t\t\tplt.plot(t,solutions[:,-3], color = \"violet\", label = 'XABC')\n",
    "\t\t\tplt.plot(t,solutions[:,-2], color = \"mediumvioletred\", label = 'XXABC')\n",
    "\n",
    "\n",
    "\n",
    "\t\tplt.plot(t,solutions[:,-1], color = \"darkviolet\", label = 'XXXABC')\n",
    "\n",
    "\n",
    "\n",
    "\t\tplt.xlabel('Time (s)')\n",
    "\t\tplt.ylabel('Concentration (uM)')\n",
    "\t\tplt.legend(loc = 'upper left', bbox_to_anchor = (1.02,1)) #prop={'size': 6}\n",
    "\t\tplt.show()\n",
    "\t\t\t \t\t\t\t\n",
    "\tdef getTotalVolume(self):\n",
    "\t\tvol = 1.0\n",
    "\t\tfor param in self.params:\t\t\n",
    "\t\t\tvol = vol*(self.parameter_values[param][\"max\"] - self.parameter_values[param][\"min\"])\n",
    "\t\treturn vol \n",
    "\n",
    "\t@staticmethod\n",
    "\t@njit\n",
    "\tdef oscillatorModelOde(Y, t, can): \n",
    "\n",
    "\t\t#parameters [kf1, kf2, kb2, kf3, kf4, kf5, kb5, kf6, kf7, kf8, kf9, kf10, kf11, kf12, kf13, kf14]\n",
    "\t\tkf1 = can[0]\n",
    "\t\tkf2 = can[1]\n",
    "\t\tkb2 = can[2]\n",
    "\t\tkf3 = can[3]\n",
    "\t\tkf4 = can[4]\n",
    "\t\tkf5 = can[5]\n",
    "\t\tkb5 = can[6]\n",
    "\t\tkf6 = can[7]\n",
    "\t\tkf7 = can[8]\n",
    "\t\tkf8 = can[9]\n",
    "\t\tkf9 = can[10]\n",
    "\t\tkf10 = can[11]\n",
    "\t\tkf11 = can[12]\n",
    "\t\tkf12 = can[13]\n",
    "\t\tkf13 = can[14]\n",
    "\t\tkf14 = can[15]\n",
    "\t\n",
    "\t\t#initial conditions\n",
    "\t\tgeneA = Y[0]   # make sure in uM\n",
    "\t\tmRNA_A = Y[1]\n",
    "\t\tA = Y[2]\n",
    "\t\tgeneA_bound = Y[3]\n",
    "\t\tgeneR = Y[4] \n",
    "\t\tmRNA_R = Y[5]\n",
    "\t\tgeneR_bound = Y[6] \n",
    "\t\tR = Y[7] \n",
    "\t\tC = Y[8] \n",
    "\n",
    "\t\tdgeneA = kb2*geneA_bound - kf2*A*geneA  \n",
    "\t\tdmRNA_A = kf1*geneA + kf3*geneA_bound - kf13*mRNA_A\n",
    "\t\tdA = kb2*geneA_bound + kb5*geneR_bound + kf7*mRNA_A - kf11*A - kf2*A*geneA - kf5*A*geneR - kf9*A*R\n",
    "\t\tdgeneA_bound = kf2*A*geneA - kb2*geneA_bound\n",
    "\t\tdgeneR = -kf4*geneR\n",
    "\t\tdmRNA_R = kf6*geneR_bound + 2*kf4*geneR - kf14*mRNA_R\n",
    "\t\tdgeneR_bound = kf5*A*geneR - kb5*geneR_bound\n",
    "\t\tdR = kf10*C + kf8*mRNA_R - kf12*R - kf9*A*R\n",
    "\t\tdC = kf9*A*R - kf10*C\n",
    "\n",
    "\t\treturn([dgeneA, dmRNA_A, dA, dgeneA_bound, dgeneR, dmRNA_R, dgeneR_bound, dR, dC])\t\n",
    "\t\n",
    "\tdef getPerAmp(self, *args, mode=\"ode\", indx=0): \n",
    "\t\tif mode == \"ode\":\n",
    "\t\t\tts = np.linspace(0, self.T, self.N*100) \n",
    "\t\t\tif len(args) == 1:\n",
    "\t\t\t\tsubject = args[0]\n",
    "\t\t\t\tY = self.simulate(subject)  \n",
    "\t\t\telse:\n",
    "\t\t\t\tinitials = args[0]\n",
    "\t\t\t\tparams = args[1]\n",
    "\t\t\t\tY = self.simulate_fixedparams(initials,params)\t\t\t\t\n",
    "\t\t#else:\n",
    "\t\t\t#ts,Y = self.represilatorStochastic(subject) \n",
    "\t\t\n",
    "\t\tts = np.array(ts) \n",
    "\t\tY = np.array(Y) \n",
    "\t\tsig = Y[:, indx]\n",
    "\t\t# indx_max, properties = signal.find_peaks(sig, prominence = (np.max(sig) - np.min(sig))/4, distance = len(ts)/100)      #old code \n",
    "\t\t# indx_min, properties = signal.find_peaks(sig*-1, prominence = (np.max(sig) - np.min(sig))/4, distance = len(ts)/100)  \n",
    "\n",
    "\t\tindx_max = peakutils.indexes(sig, thres=0.5, min_dist=1)\n",
    "\t\tindx_min = peakutils.indexes(sig*-1, thres=0.5, min_dist=1)   \n",
    "\n",
    "\t\tamps = [] \n",
    "\t\tpers = []   \n",
    "\t\tfor i in range(min(len(indx_max), len(indx_min))):\n",
    "\t\t\tamps.append((sig[indx_max[i]] - sig[indx_min[i]])/2) \t\t\t\n",
    "\t\t\tif i + 1 < len(indx_max):\n",
    "\t\t\t\tpers.append(ts[indx_max[i + 1]] - ts[indx_max[i]])\n",
    "\t\t\tif i + 1 < len(indx_min):\n",
    "\t\t\t\tpers.append(ts[indx_min[i + 1]] - ts[indx_min[i]])\n",
    "\t\t\n",
    "\t\tif len(amps) > 0 and len(pers) > 0:\n",
    "\t\t\tamps = np.array(amps)   \t\n",
    "\t\t\tpers = np.array(pers)  \n",
    "\t\t\t\n",
    "\t\t\t#print(amps)\n",
    "\t\t\tamp = np.mean(amps)\t\n",
    "\t\t\t#print(pers) \n",
    "\t\t\tper = np.mean(pers) \n",
    "\t\telse:\n",
    "\t\t\tamp = 0\n",
    "\t\t\tper = 0  \n",
    "\t\t\n",
    "\t\t#print(\"amp\" + str(amp)) \n",
    "\t\t#print(\"per\" + str(per))   \t\n",
    "\t\t\n",
    "\t\treturn per, amp \n",
    "\n",
    "\t#@njit\n",
    "\tdef ssa(self, candidate):\n",
    "\t\t#omega = self.omega\n",
    "\t\t#y0 = [can[13],0,can[14],can[15],0,can[16],0,0,0,0,0,0]\n",
    "\t\t#y0 = [self.copynumber(i) for i in self.y0]\n",
    "\n",
    "\t\t# y0 = [candidate[0],candidate[1],candidate[2],candidate[3],0,candidate[4],0,0,0,0,0,0]\n",
    "\t\t# copynumbers = [self.copynumber(x) for x in candidate]\n",
    "\n",
    "\t\ty_conc = np.array(self.copynumbers).astype(int) \n",
    "\t\tY_total = []\n",
    "\t\tY_total.append(y_conc)\n",
    "\t\tt = 0 \n",
    "\t\tt_end = 100\n",
    "\t\tT = []   \n",
    "\t\tT.append(t)\n",
    "\t\t\n",
    "\t\tcan = candidate\n",
    "\t\t#get kinetic rates \n",
    "\t\ty = can[12]\n",
    "\t\t\n",
    "\t\tka1 = can[0]\n",
    "\t\tkb1 = can[1]\n",
    "\t\tkcat1 = can[2]\n",
    "\n",
    "\t\tka2 = can[3]\n",
    "\t\tkb2 = can[4]\n",
    "\n",
    "\t\tka3 = can[5]\n",
    "\t\tkb3 = can[6]\n",
    "\n",
    "\t\tka4 = can[7]\n",
    "\t\tkb4 = can[8]\n",
    "\n",
    "\t\tka7 = can[9]\n",
    "\t\tkb7 = can[10]\n",
    "\t\tkcat7 = can[11]\n",
    "\n",
    "\t\tka5 = can[9]*y\n",
    "\t\tkb5 = can[10]\n",
    "\t\tkcat5 = can[11]\n",
    "\n",
    "\t\tka6 = can[0]*y\n",
    "\t\tkb6 = can[1]\n",
    "\t\tkcat6 = can[2]\n",
    "\n",
    "\t\tka8 = can[13]\n",
    "\t\tkb8 = can[14]\n",
    "\t\t\n",
    "\t\tN = np.zeros((20,14)) #6 species, 15 reactions\n",
    "\t\t#L+K -> LK\n",
    "\t\tN[0,0] = -1 \n",
    "\t\tN[0,2] = -1 \n",
    "\t\tN[0,4] = 1\n",
    "\n",
    "\t\t#LK -> L+K\n",
    "\t\tN[1,0] = 1\n",
    "\t\tN[1,2] = 1\n",
    "\t\tN[1,4] = -1\n",
    "\n",
    "\t\t#LK -> Lp+K\n",
    "\t\tN[2,4] = -1\n",
    "\t\tN[2,1] = 1\n",
    "\t\tN[2,2] = 1\n",
    "\n",
    "\t\t#Lp+A -> LpA\n",
    "\t\tN[3,1] = -1\n",
    "\t\tN[3,5] = -1\n",
    "\t\tN[3,6] = 1\n",
    "\n",
    "\t\t#LpA -> Lp+A\n",
    "\t\tN[4,1] = 1\n",
    "\t\tN[4,5] = 1\n",
    "\t\tN[4,6] = -1\n",
    "\t\t\n",
    "\t\t#LpA + K -> LpAK\n",
    "\t\tN[5,6] = -1 \n",
    "\t\tN[5,2] = -1\n",
    "\t\tN[5,7] = 1\n",
    "\n",
    "\t\t#LpAK -> LpA + K\n",
    "\t\tN[6,6] = 1\n",
    "\t\tN[6,2] = 1\n",
    "\t\tN[6,7] = -1 \n",
    "\t\t\n",
    "\t\t#L + LpAK -> LpAKL\n",
    "\t\tN[7,0] = -1\n",
    "\t\tN[7,7] = -1\n",
    "\t\tN[7,10] = 1\n",
    "\n",
    "\t\t#LpAKL -> L + LpAK\n",
    "\t\tN[8,0] = 1\n",
    "\t\tN[8,7] = 1\n",
    "\t\tN[8,10] = -1\n",
    "\n",
    "\t\t#LpAKL -> Lp + LpAK\n",
    "\t\tN[9,10] = -1\n",
    "\t\tN[9,1] = 1\n",
    "\t\tN[9,7] = 1\n",
    "\n",
    "\t\t#Lp + P -> LpP\n",
    "\t\tN[10,1] = -1\n",
    "\t\tN[10,3] = -1\n",
    "\t\tN[10,11] = 1\n",
    "\n",
    "\t\t#LpP -> Lp + P\n",
    "\t\tN[11,1] = 1\n",
    "\t\tN[11,3] = 1\n",
    "\t\tN[11,11] = -1\n",
    "\n",
    "\t\t#LpP -> L + P\n",
    "\t\tN[12,11] = -1\n",
    "\t\tN[12,0] = 1\n",
    "\t\tN[12,3] = 1\n",
    "\n",
    "\t\t#LpA + P -> LpAP\n",
    "\t\tN[13,6] = -1\n",
    "\t\tN[13,3] = -1\n",
    "\t\tN[13,8] = 1\n",
    "\n",
    "\t\t#LpA + P <- LpAP\n",
    "\t\tN[14,6] = 1\n",
    "\t\tN[14,3] = 1\n",
    "\t\tN[14,8] = -1\n",
    "\n",
    "\t\t#Lp + LpAP -> LpAPLp\n",
    "\t\tN[15,1] = -1\n",
    "\t\tN[15,8] = -1\n",
    "\t\tN[15,9] = 1\n",
    "\n",
    "\t\t#Lp + LpAP <- LpAPLp\n",
    "\t\tN[16,1] = 1\n",
    "\t\tN[16,8] = 1\n",
    "\t\tN[16,9] = -1\n",
    "\n",
    "\t\t#LpAPLp -> L + LpAP\n",
    "\t\tN[17,9] = -1\n",
    "\t\tN[17,0] = 1\n",
    "\t\tN[17,8] = 1 \n",
    "\n",
    "\t\t#LpA + T -> LpAT \n",
    "\t\tN[18,6] = -1\n",
    "\t\tN[18,12] = -1\n",
    "\t\tN[18,13] = 1\n",
    "\n",
    "\t\t#LpA + T <- LpAT \n",
    "\t\tN[19,6] = 1\n",
    "\t\tN[19,12] = 1\n",
    "\t\tN[19,13] = -1\n",
    "\t\t\n",
    "\t\twhile t < t_end:\n",
    "\t\t\t#choose two random numbers \n",
    "\t\t\tr = np.random.uniform(size=2)\n",
    "\t\t\tr1 = r[0] \n",
    "\t\t\tr2 = r[1] \t\t\t\t\t\n",
    "\t\t\t\n",
    "\t\t\t#get propensities\n",
    "\t\t\ta = np.zeros(len(N))\n",
    "\t\t\ta[0] = ka1*y_conc[0]*y_conc[2] \n",
    "\t\t\ta[1] = kb1*y_conc[4]\n",
    "\t\t\ta[2] = kcat1*y_conc[4]  \n",
    "\t\t\t\n",
    "\t\t\ta[3] = ka2*y_conc[1]*y_conc[5] \n",
    "\t\t\ta[4] = kb2*y_conc[6]\n",
    "\n",
    "\t\t\ta[5] = ka3*y_conc[6]*y_conc[2]\n",
    "\t\t\ta[6] = kb3*y_conc[7]\n",
    "\n",
    "\t\t\ta[7] = ka6*y_conc[0]*y_conc[7]\n",
    "\t\t\ta[8] = kb6*y_conc[10]\n",
    "\t\t\ta[9] = kcat6*y_conc[10]\n",
    "\n",
    "\t\t\ta[10] = ka7*y_conc[1]*y_conc[3]\n",
    "\t\t\ta[11] = kb7*y_conc[11]\n",
    "\t\t\ta[12] = kcat7*y_conc[11]\n",
    "\n",
    "\t\t\ta[13] = ka4*y_conc[6]*y_conc[3]\n",
    "\t\t\ta[14] = kb4*y_conc[8]\n",
    "\n",
    "\t\t\ta[15] = ka5*y_conc[1]*y_conc[8]\n",
    "\t\t\ta[16] = kb5*y_conc[9]\n",
    "\t\t\ta[17] = kcat5*y_conc[9]  \n",
    "\n",
    "\t\t\ta[18] = ka8*y_conc[6]*y_conc[12]\n",
    "\t\t\ta[19] = kb8*y_conc[13]\n",
    "\t\t\t\n",
    "\t\t\tasum = np.cumsum(a)\n",
    "\t\t\ta0 = np.sum(a)  \n",
    "\t\t\t#get tau\n",
    "\t\t\ttau = (1.0/a0)*np.log(1.0/r1)     \n",
    "\t\t\n",
    "\t\t\t#select reaction \n",
    "\t\t\treaction_number = np.argwhere(asum > r2*a0)[0,0] #get first element\t\t\t\n",
    "\t\t\n",
    "\t\t\t#update concentrations\n",
    "\t\t\ty_conc = y_conc + N[reaction_number,:]   \t\n",
    "\t\t\tY_total.append(y_conc) \n",
    "\t\t\t#update time\n",
    "\t\t\tt = t + tau  \n",
    "\t\t\tT.append(t)\n",
    "\t\tT = np.array(T) \n",
    "\t\tdeconvert = np.vectorize(self.concentration)\n",
    "\t\tY_total = np.array(Y_total) \n",
    "\t\treturn T, deconvert(Y_total) \n",
    "\n",
    "\tdef copynumber(self, conc):\n",
    "\t\tvolume = self.volume/1e15 #converts liters to um^3\n",
    "\t\tconc = conc/1e6 #converts umol to mol\n",
    "\t\tmoles = conc * volume #volume must be passed in um^-3\n",
    "\t\tcopies = moles * 6.023e23\n",
    "\t\treturn copies\n",
    "\n",
    "\tdef concentration(self, copies):\n",
    "\t\tmoles = copies/6.023e23\n",
    "\t\tvolume = self.volume/1e15\n",
    "\t\tconc = moles/volume \n",
    "\t\treturn conc*1e6\n",
    "\n",
    "\tdef rate_converter(self, rate, ode = False):\n",
    "\t\t#convert ka in (uM*s)^-1 to nm^3/us\n",
    "\t\tif ode == True:\n",
    "\t\t\trate1 = rate/0.602214076 ##conversion ratio from page 10 of NERDSS manual\n",
    "\t\t\trate2 = rate1*1e6 ##convert from us to s\n",
    "\t\t\tvolume = self.volume*1e9 #convert volume to nm3\n",
    "\t\t\treturn rate2/volume ##calculate copy numbers per second\n",
    "\t\telse: #else kb or kcat in s^-1\n",
    "\t\t\t#new_rate = rate / 1e6 #convert per second to per microsecond\n",
    "\t\t\treturn rate/0.602214076 \n",
    "\n",
    "\tdef full_converter(self, sample, ode = False):\n",
    "\t\tnew_sample = []\n",
    "\t\tfor i,val in enumerate(sample): \n",
    "\t\t\tif i == 0 or i ==3 or i ==5 or i==7 or i==9 or i==13:\n",
    "\t\t\t\tnew_sample.append(self.rate_converter(val, ode))\n",
    "\t\t\telif i==1 or i==2 or i==4 or i==6 or i==8 or i==10 or i==11 or i==14:\n",
    "\t\t\t\tnew_sample.append(val)\n",
    "\t\t\telif i==12 and ode==True:\n",
    "\t\t\t\tnew_sample.append(val/(2*self.sigma))\n",
    "\t\t\telse:\n",
    "\t\t\t\tnew_sample.append(val)\n",
    "\t\t# new_sample.extend(self.copynumbers)\n",
    "\t\t\t\n",
    "\t\treturn new_sample\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Regions consist of cloud of points and principal component that govern the direction of exploration  \n",
    "''' \n",
    "class Region: \n",
    "\tdef __init__(self, points, model, label, depth=1):    \n",
    "\t\tself.points = np.array(points)  \n",
    "\t\tself.model = model  \n",
    "\t\tself.pca = PCA(n_components=self.model.nParams)\n",
    "\t\tself.components = None\n",
    "\t\tself.prevComponents = None \n",
    "\t\tself.cluster = False\n",
    "\t\tself.terminated = False  \n",
    "\t\tself.iter = 0      \n",
    "\t\tself.maxIter = 10            \n",
    "\t\tself.threshold = 0.001    \n",
    "\t\tself.label = label\n",
    "\t\tself.maxVarScale = 4\n",
    "\t\tself.minVarScale = 2   \n",
    "\t\tself.varScaleDt = (self.maxVarScale - self.minVarScale)/(float(self.maxIter))    \t\t     \t\t\n",
    "\t\tself.varScale = self.maxVarScale         \n",
    "\t\tself.depth = depth  \n",
    "\t\t\n",
    "\tdef updateVariance(self): \n",
    "\t\tself.varScale = self.varScale - self.varScaleDt\n",
    "\n",
    "\tdef updateIter(self):\n",
    "\t\tself.iter = self.iter + 1\n",
    "\t\tself.updateVariance()          \t\n",
    "\t\t\n",
    "\tdef fitPCA(self): \n",
    "\t\tself.prevComponents = self.components \n",
    "\t\tself.pca.fit(self.points)\n",
    "\t\tself.components = self.pca.components_\n",
    "\t\n",
    "\tdef transform(self, points):  \n",
    "\t\treturn self.pca.transform(points)  \n",
    "\t\t\n",
    "\tdef inverse_transform(self, points):\n",
    "\t\treturn self.pca.inverse_transform(points)   \n",
    "\t\t\n",
    "\tdef converged(self):\n",
    "\t\tif self.components is None or self.prevComponents is None: \n",
    "\t\t\treturn False\t\t\n",
    "\t\treturn np.linalg.norm(self.components - self.prevComponents) < self.threshold   \n",
    "\t\t\n",
    "\tdef explored(self):    \n",
    "\t\treturn self.terminated or self.iter > self.maxIter or self.converged()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The main class\n",
    "'''\n",
    "from genericpath import isdir\n",
    "\n",
    "\n",
    "class Solver:\n",
    "\tdef __init__(self, model, name, populationSize=10000, NGEN = 10, nsamples = 1e5, writeparms = False, verbose=True, auto = False):                                                      \n",
    "\t\tself.model = model \n",
    "\t\tself.name = name           \n",
    "\t\tself.populationSize = populationSize         \n",
    "\t\tself.NGEN = NGEN  \n",
    "\t\tself.nsamples = int(nsamples) \t\n",
    "\t\tself.indpb = 0.9 #from 0.75    \n",
    "\t\t#self.copynumbers = [self.copynumber(x) for x in model.y0]\n",
    "\t\tself.centerpoints = {}\t\n",
    "\t\tself.writeparms = writeparms\n",
    "\t\tself.verbose = verbose\n",
    "\t\tself.auto = auto \n",
    "\t\tself.num_jobs = 0\n",
    "\t\t\n",
    "\t\t#GA operators\n",
    "\t\tcreator.create(\"FitnessMax\", base.Fitness, weights=(1.0,)) \n",
    "\t\tcreator.create(\"Candidate\", list, fitness=creator.FitnessMax)  \t\t\n",
    "\t\tself.toolbox = base.Toolbox()\t \n",
    "\t\tself.toolbox.register(\"candidate\", self.generateCandidate) \n",
    "\t\tself.toolbox.register(\"population\", tools.initRepeat, list, self.toolbox.candidate)  \n",
    "\t\tself.toolbox.register(\"mate\", tools.cxTwoPoint)\n",
    "\t\tself.toolbox.register(\"mutate\", self.mutateCandidate, indpb=self.indpb, mult=0.5)      \n",
    "\t\tself.toolbox.register(\"select\", tools.selTournament, tournsize=int(self.populationSize/10))     \t\t\n",
    "\t\n",
    "\t#### functions for printing NERDSS parameters ####\n",
    "\tdef waterbox(self,VA):\n",
    "\t\tV = self.model.volume * 1e9 #convert um3 to nm3\n",
    "\t\tVA = VA * 1000 #convert um to nm \n",
    "\n",
    "\t\tA = V/VA #units of nm2\n",
    "\t\tx = round(np.sqrt(A))\n",
    "\t\ty = round(np.sqrt(A))\n",
    "\t\tz = round(VA) \n",
    "\n",
    "\t\tdimensions = [x,y,z]\n",
    "\t\t#ztest = z/10\n",
    "\t\t#xtest = np.sqrt(V/ztest)\n",
    "\t\t#ytest = np.sqrt(V/ztest)\n",
    "\n",
    "\t\t#test = (ztest*xtest*ytest)/(xtest*ytest)\n",
    "\n",
    "\t\treturn dimensions\n",
    "\n",
    "\t#estimate initial values with GA\n",
    "\tdef findNominalValues(self):    \t \t\n",
    "\t\tnominalVals = []   \n",
    "\t\t\n",
    "\t\tfor evalMode in self.model.modes: \n",
    "\t\t\tnominalValsMode = []\n",
    "\t\t\tself.toolbox.register(\"evaluate\", evalMode)   \n",
    "\t\t\t#initialize new random population\n",
    "\t\t\tself.popu = self.toolbox.population(self.populationSize)  \t \n",
    "\t\t\t\n",
    "\t\t\tfor gen in range(self.NGEN):  \n",
    "\t\t\t\tprint(gen)\n",
    "\t\t\t\t#generate offspprings with crossover and mutations\n",
    "\t\t\t\toffspring = algorithms.varAnd(self.popu, self.toolbox, cxpb=0.5, mutpb=0.75)  \n",
    "\t\t\t\t#evaluate individuals\n",
    "\t\t\t\tfits = self.toolbox.map(self.toolbox.evaluate, offspring) \n",
    "\t\t\t\tfor fit, ind in zip(fits, offspring): \n",
    "\t\t\t\t\tif self.model.isViable(ind) and ind not in nominalValsMode:  \n",
    "\t\t\t\t\t\tnominalValsMode.append(ind)      \n",
    "\t\t\t\t\tind.fitness.values = fit     \n",
    "\t\t\t\t#roulete wheel selection\n",
    "\t\t\t\tself.popu = self.toolbox.select(offspring, k=len(self.popu)) \n",
    "\t\t\t\t\n",
    "\t\t\t\trando = np.random.randint(0, len(self.popu))\n",
    "\t\t\t\trdm_ind = self.popu[rando]\n",
    "\t\t\t\tprint(rdm_ind)\n",
    "\t\t\t\t# rdm_ind_label = {}\n",
    "\n",
    "\t\t\t\t# for parameter, value in zip(self.model.parameter_values.keys(), rdm_ind):\n",
    "\t\t\t\t# \trdm_ind_label[parameter] = value\n",
    "\n",
    "\n",
    "\t\t\t\t# #print(rdm_ind_label)\n",
    "\n",
    "\t\t\t\t# kadic = {'ka1':rdm_ind[0],'ka2':rdm_ind[3],'ka3':rdm_ind[5],'ka4':rdm_ind[7],'ka7':rdm_ind[9]}\n",
    "\t\t\t\t# kbdic = {'kb1':rdm_ind[1],'kb2':rdm_ind[4],'kb3':rdm_ind[6],'kb4':rdm_ind[8],'kb7':rdm_ind[10]}\n",
    "\t\t\t\t# kcatdic = {'kcat1':rdm_ind[2],'kcat7':rdm_ind[11]}\n",
    "\t\t\t\t# KDdic = {'Km1':(rdm_ind[1]+rdm_ind[2])/rdm_ind[0],'Kd2':rdm_ind[4]/rdm_ind[3],'Kd3':rdm_ind[6]/rdm_ind[5],'Kd4':rdm_ind[8]/rdm_ind[7],'Km7':(rdm_ind[10]+rdm_ind[11])/rdm_ind[9]}\n",
    "\t\t\t\t# comparison_list = [kadic,kbdic,kcatdic,KDdic]\n",
    "\n",
    "\t\t\t\t# for h in comparison_list:\n",
    "\t\t\t\t# \t#sorted_dict = {}\n",
    "\t\t\t\t# \tsorted_keys = sorted(h, key=h.get)  # [1, 3, 2]\n",
    "\n",
    "\t\t\t\t# \tstring = str()\n",
    "\t\t\t\t# \tfor i in range(len(sorted_keys)):\n",
    "\t\t\t\t# \t\tstring += sorted_keys[i] + \" < \"\n",
    "\t\t\t\t# \tif self.verbose:\n",
    "\t\t\t\t# \t\tprint(string)\n",
    "\t\t\t\t\n",
    "\t\t\t\t# #calculate waterbox dimensions for NERDSS\n",
    "\t\t\t\t# waterbox = self.waterbox(rdm_ind[12])\n",
    "\n",
    "\t\t\t\t# #convert parameters for NERDSS\n",
    "\t\t\t\t# NERDSSparamlist = []\n",
    "\t\t\t\t# parmslist = []\n",
    "\t\t\t\t# ODElist = []\n",
    "\t\t\t\t# for param in rdm_ind_label.items():\n",
    "\t\t\t\t# \tif 'ka' in param[0]:\n",
    "\t\t\t\t# \t\tconverted_rate = self.model.rate_converter(param[1])\n",
    "\t\t\t\t# \t\tNERDSSparamlist.append(param[0] + ': ' + str(converted_rate) + ' nm^3/us')\n",
    "\t\t\t\t# \t\tparmslist.append(str(converted_rate))\n",
    "\t\t\t\t# \t\tconverted_rate_ode = self.model.rate_converter(param[1],True)\n",
    "\t\t\t\t# \t\tODElist.append(converted_rate_ode)\n",
    "\t\t\t\t# \telif 'kb' in param[0] or 'kcat' in param[0]:\n",
    "\t\t\t\t# \t\t#converted_rate = self.rate_converter(param[1], ka = False)\n",
    "\t\t\t\t# \t\tNERDSSparamlist.append(param[0] + ': ' + str(param[1]) + ' s^-1')\n",
    "\t\t\t\t# \t\tparmslist.append(str(param[1]))\n",
    "\t\t\t\t# \t\tODElist.append(param[1])\n",
    "\t\t\t\t# \telif 'VA' in param[0]:\n",
    "\t\t\t\t# \t\tgamma = param[1]/(2*self.model.sigma)\n",
    "\t\t\t\t# \t\tODElist.append(gamma)\n",
    "\n",
    "\t\t\t\t# NERDSSparamlist.append('sigma: ' + str((self.model.sigma)*1e3))\n",
    "\t\t\t\t# ODElist.extend(self.model.copynumbers)\n",
    "\t\t\t\t# # OGparamlist = rdm_ind.extend(self.model.y0)\n",
    "\n",
    "\t\t\t\t# #write parms \n",
    "\t\t\t\t# if self.writeparms == True:\n",
    "\t\t\t\t# \tself.write_parms(parmslist, waterbox, gen, os.getcwd())\n",
    "\n",
    "\t\t\t\t# #print parameters \n",
    "\t\t\t\t# if self.verbose:\n",
    "\t\t\t\t# \tprint('Original parameters with concentration units:' + '\\n')\n",
    "\t\t\t\t# \tprint(rdm_ind_label)\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t# \tprint('\\n'+ 'NERDSS parameters' + '\\n')\n",
    "\t\t\t\t# \tprint(NERDSSparamlist)\n",
    "\n",
    "\t\t\t\t# \tprint('\\n'+ 'Waterbox dimensions' + '\\n')\n",
    "\t\t\t\t# \tprint(waterbox)\n",
    "\n",
    "\t\t\t\t# \tprint('\\n' + 'ODE test parameters' + '\\n')\n",
    "\t\t\t\t# \tprint(ODElist)\n",
    "\n",
    "\t\t\t\t# \tprint(\"Number of viable points: \" + str(len(nominalValsMode))) \n",
    "\n",
    "\t\t\t\t# \tprint(self.model.isViable(rdm_ind))\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t# \tcost, penalty = self.model.eval(rdm_ind)\n",
    "\t\t\t\t# \tprint('Cost: ' + str(cost))\n",
    "\t\t\t\t# \ttry:\n",
    "\t\t\t\t# \t\tprint('Frequency penalty: ' + str(penalty))\n",
    "\t\t\t\t# \texcept IndexError:\n",
    "\t\t\t\t# \t\tpass \n",
    "\t\t\t\tself.model.plotModel(rdm_ind)\n",
    "\t\t\t\tself.model.plotModel(rdm_ind, lipid = False)\n",
    "\n",
    "\t\t\t\t# self.model.plotModel(rdm_ind,mode=\"ssa\")\n",
    "\n",
    "\t\t\tprint(\"Number of viable points: \" + str(len(nominalValsMode))) \n",
    "\t\t\tnominalVals.extend(nominalValsMode)     \n",
    "\t\treturn nominalVals        \n",
    "\n",
    "\n",
    "\t#creates an array of random candidates  \n",
    "\tdef generateCandidate(self): \n",
    "\t\tcandidate = []\n",
    "\t\tfor ind in range(self.model.nParams): \n",
    "\t\t\t#try:\n",
    "\t\t\t\t#candidate.append(loguniform.rvs(self.model.parameter_values[self.model.params[ind]][\"min\"], self.model.parameter_values[self.model.params[ind]][\"max\"]))\n",
    "\t\t\t#except ValueError:\n",
    "\t\t\tcandidate.append(random.uniform(self.model.parameter_values[self.model.params[ind]][\"min\"], self.model.parameter_values[self.model.params[ind]][\"max\"]))\n",
    "\t\treturn creator.Candidate(candidate) \t\n",
    "\t\t\n",
    "\tdef checkOutAllBounds(self, candidate):\n",
    "\t\tfor idx, val in enumerate(candidate):\n",
    "\t\t\tif self.checkOutOfBounds(candidate, idx): \n",
    "\t\t\t\treturn True  \n",
    "\t\treturn False      \n",
    "\t\t\t\t\n",
    "\tdef checkOutOfBounds(self, candidate, idx): \n",
    "\t\t#if out of bounds return True \n",
    "\t\tif candidate[idx] < self.model.parameter_values[self.model.params[idx]][\"min\"] or candidate[idx] > self.model.parameter_values[self.model.params[idx]][\"max\"]: \n",
    "\t\t\treturn True\n",
    "\t\treturn False    \t\t\n",
    "\t\n",
    "\t#returns a tuple of mutated candidate\t\n",
    "\tdef mutateCandidate(self, candidate, indpb, mult): \t\n",
    "\t\tfor idx, val in enumerate(candidate):\t\n",
    "\t\t\trnd = random.uniform(0, 1)\n",
    "\t\t\tif rnd <= indpb:\n",
    "\t\t\t\trnd2 = random.uniform(1 - mult, 1 + mult)   \n",
    "\t\t\t\tcandidate[idx] = val*rnd2\t\n",
    "\t\t\t\tif candidate[idx] < self.model.parameter_values[self.model.params[idx]][\"min\"]: \n",
    "\t\t\t\t\tcandidate[idx] = self.model.parameter_values[self.model.params[idx]][\"min\"]  \n",
    "\t\t\t\tif candidate[idx] > self.model.parameter_values[self.model.params[idx]][\"max\"]:  \n",
    "\t\t\t\t\tcandidate[idx] = self.model.parameter_values[self.model.params[idx]][\"max\"]    \t\t\t\t\t\n",
    "\t\treturn candidate,     \n",
    "\t\n",
    "\tdef getViablePoints(self, points):\n",
    "\t\tviable = list() \n",
    "\t\ti = 0\n",
    "\t\tfor point in points:  \n",
    "\t\t\ti += 1\n",
    "\t\t\tif i % 1000 == 0:\n",
    "\t\t\t\tprint(i)     \n",
    "\t\t\t\n",
    "\t\t\t#check if point is viable \n",
    "\t\t\tif self.model.isViable(point): \n",
    "\t\t\t\tviable.append(point)   \t\t\n",
    "\t\treturn viable          \n",
    "\t\n",
    "\t# gap statistic method\n",
    "\t# returns the optimal number of clusters \t\n",
    "\tdef gapStatistic(self, region, number_ref = 10, max_clusters = 2, plot = False):        \n",
    "\t\t#sample size is equal to the number of samples in gaussian sampling  \n",
    "\t\tsample_size = self.nsamples    \n",
    "\t\tsubjects = np.array(region.points)                 \n",
    "\t\tgaps = []\n",
    "\t\tdeviations = []   \n",
    "\t\treferences = [] \n",
    "\t\tclusters_range = range(1, max_clusters + 1) \n",
    "\t\t\n",
    "\t\ttransformed = region.transform(subjects) \n",
    "\t\t#get min and max parameter values in pca space \n",
    "\t\tminP = np.min(transformed, axis=0)  \n",
    "\t\tmaxP = np.max(transformed, axis=0)   \n",
    "\t\t\n",
    "\t\tfor gap_clusters in clusters_range:\n",
    "\t\t\tprint(gap_clusters) \n",
    "\t\t\treference_inertia = []\t\n",
    "\t\t\tfor index in range(number_ref): \n",
    "\n",
    "\t\t\t\t#OBB ... orientated bounding box \n",
    "\t\t\t\t#random sampling within the PCA bounding box\t\t\t\n",
    "\t\t\t\treference = minP + random.rand(sample_size, self.model.nParams)*(maxP - minP)\n",
    "\t\t\t\treference = region.inverse_transform(reference) \n",
    "\t\t\t\t\n",
    "\t\t\t\tkmeanModel = KMeans(gap_clusters) \n",
    "\t\t\t\tkmeanModel.fit(reference) \n",
    "\t\t\t\treference_inertia.append(kmeanModel.inertia_)    \n",
    "\t\t\t\n",
    "\t\t\tkmeanModel = KMeans(gap_clusters)      \n",
    "\t\t\tkmeanModel.fit(subjects)     \n",
    "\t\t\tlog_ref_inertia = np.log(reference_inertia)\t \n",
    "\t\t\t#calculate gap\n",
    "\t\t\tgap = np.mean(log_ref_inertia) - np.log(kmeanModel.inertia_)  \n",
    "\t\t\tsk = math.sqrt(1 + 1.0/number_ref)*np.std(log_ref_inertia)  \n",
    "\t\t\tgaps.append(gap)    \n",
    "\t\t\tdeviations.append(sk)        \t\t\t\n",
    "\t\t\t\n",
    "\t\t# Plot the gaps   \t\t\n",
    "\t\tif plot:\n",
    "\t\t\tplt.clf() \n",
    "\t\t\tax = plt.gca() \n",
    "\t\t\tax.xaxis.set_major_locator(ticker.MaxNLocator(integer=True))\t \n",
    "\t\t\tax.xaxis.set_major_locator(ticker.MultipleLocator(2))\t\n",
    "\t\t\tlines = plt.errorbar(clusters_range, gaps, ecolor='dodgerblue', yerr=deviations, fmt='-', color='dodgerblue') \n",
    "\t\t\tplt.setp(lines[0], linewidth=1.5)  \n",
    "\t\t\tplt.ylabel('Gaps')\n",
    "\t\t\tplt.show()  \n",
    "\t\t\t\n",
    "\t\t#return optimal number of clusters\n",
    "\t\tfor k in range(0, max_clusters - 1): \n",
    "\t\t\tif gaps[k] >= gaps[k + 1] - deviations[k + 1]: \n",
    "\t\t\t\tprint(\"Optimal number of clusters: \" + str(k + 1)) \n",
    "\t\t\t\treturn k + 1     \n",
    "\t\tprint(\"Optimal number of clusters: \" + str(max_clusters))    \t\n",
    "\t\treturn max_clusters   \n",
    "\n",
    "\t\n",
    "\t#returns the viable volume for \n",
    "\tdef getViableVolume(self, viableRegions, sample_size = int(1e4)):\n",
    "\t\tvolume = 0 \n",
    "\n",
    "\t\tfor region in viableRegions:\t\t\n",
    "\t\t\tregPoints = region.points\n",
    "\t\t\tregion.fitPCA() \t\t\t\t\t\t \t\t\t\t\t\t\n",
    "\t\t\ttransformed = region.transform(regPoints) \n",
    "\t\t  \t\t\n",
    "\t\t\tminP = np.min(transformed, axis=0)   \n",
    "\t\t\tmaxP = np.max(transformed, axis=0)   \n",
    "\t\t\n",
    "\t\t\tdP = maxP - minP\n",
    "\t\t\tvolB = np.prod(dP)\t\t\t\n",
    "\n",
    "\t\t\tmcRef = minP + random.rand(sample_size, self.model.nParams)*dP  \n",
    "\t\t\tmcRef = region.inverse_transform(mcRef)\t \t\t\n",
    "\t\t\t\n",
    "\t\t\tviaPoints = self.getViablePoints(mcRef) \n",
    "\t\t\tcount = np.ma.size(viaPoints, axis=0) \n",
    "\t\t\t\n",
    "\t\t\t#volume for region  \n",
    "\t\t\tratio = count/sample_size   \n",
    "\t\t\tvolume = volume + ratio*volB  \t\t\t\n",
    "\t\n",
    "\t\tprint(\"Bounding box volume \" + str(volB)) \n",
    "\t\tprint(\"Volume \" + str(volume))   \n",
    "\t\tprint(\"Total volume \" + str(self.model.getTotalVolume()))   \t\t\n",
    "\t\tprint(\"Volume ratio:\" + str(volume/self.model.getTotalVolume())) \n",
    "\t\treturn volume \n",
    "\n",
    "\n",
    "\tdef setBoxColors(self, bp, nRegions, ax, colors = [\"#0E74C8\", \"#15A357\", \"r\", \"k\"]):\n",
    "\t\tcolorLen = len(colors) \n",
    "\n",
    "\t\tfor i in range(nRegions): \n",
    "\t\t\tcol = colors[i % colorLen] \t\t \n",
    "\t\t\tplt.setp(bp['boxes'][i], color=col, linewidth=1.5)    \n",
    "\t\t\tplt.setp(bp['caps'][2*i], color=col, linewidth=1.5)  \n",
    "\t\t\tplt.setp(bp['caps'][2*i + 1], color=col, linewidth=1.5) \n",
    "\t\t\tplt.setp(bp['whiskers'][2*i], color=col, linewidth=1.5)  \n",
    "\t\t\tplt.setp(bp['whiskers'][2*i + 1], color=col, linewidth=1.5)   \n",
    "\t\t\tplt.setp(bp['fliers'][i], color=col) \n",
    "\t\t\tplt.setp(bp['medians'][i], color=col, linewidth=1.5)   \n",
    "\t\t\n",
    "\tdef plotParameterVariances(self, viableSets, names=None, units=None):      \n",
    "\t\t#go through all parameters  \n",
    "\t\tparams = self.model.params    \n",
    "\t\tfigure = plt.figure()     \n",
    "\t\tnRows = math.ceil(len(params)/3)    \n",
    "\t\tfor pcount, param in enumerate(params):    \n",
    "\t\t\tax1 = plt.subplot(nRows, 3, pcount+1)  \n",
    "\t\t\t#if names == None:\n",
    "\t\t\t#\tax1.set_title(str(param) + str(pcount))    \n",
    "\t\t\t#else:\n",
    "\t\t\t#\tax1.set_title(names[pcount])  \n",
    "\t\t\tif units != None:\n",
    "\t\t\t\tplt.ylabel(names[pcount] + \" \" + units[pcount])  \n",
    "\t\t\tallRegions = [] \t\n",
    "\t\t\t#go through all regions \n",
    "\t\t\tnumSets = len(viableSets) \n",
    "\t\t\tallNames = []\n",
    "\t\t\tallBoxes = []\n",
    "\t\t\tfor count, reg in enumerate(viableSets): \n",
    "\t\t\t\tpoints = np.array(reg.points)    \n",
    "\t\t\t\tdata = points[:,pcount]   \n",
    "\t\t\t\tallRegions.append(data)   \n",
    "\t\t\t\tallNames.append(\"Region \" + str(count + 1))   \t\t\t\t\n",
    "\t\t\tbp = ax1.boxplot(allRegions, positions=list(range(1, numSets + 1)), widths = 0.4) \n",
    "\t\t\tself.setBoxColors(bp, numSets, ax1) \t\t\n",
    "\t\t\tallBoxes = bp['boxes'] \n",
    "\t\t\t\n",
    "\t\t#draw legend \n",
    "\t\tfigure.legend(allBoxes, allNames, 'lower right')\n",
    "\t\tplt.show()     \n",
    "\t\t\n",
    "\t#Main method  \n",
    "\tdef run(self, filename, maxDepth=0):    \n",
    "\t\t#filename is a file to which viable sets will be serialized\n",
    "\t\tif not os.path.isdir(\"ViableSets\"):  \n",
    "\t\t\tos.mkdir(\"ViableSets\")\n",
    "\t\tif not os.path.isdir(\"CandidateSets\"): \n",
    "\t\t\tos.mkdir(\"CandidateSets\")\n",
    "\t\tif not os.path.isdir(\"PDFs\"): \n",
    "\t\t\tos.mkdir(\"PDFs\")\n",
    "\t\tviablesets_filename = \"./ViableSets/\" + filename  \n",
    "\n",
    "\t\t#estimate the inital viable set \n",
    "\t\tviablePoints = self.findNominalValues()         \t\t                 \t\t\n",
    "\t\t\n",
    "\t\tif not viablePoints: \n",
    "\t\t\tprint(\"No viable points found!\")  \n",
    "\t\t\treturn \n",
    "\t\t\n",
    "\t\t#dump viable points to file  \n",
    "\t\tpickle.dump(viablePoints, open(viablesets_filename + \"ViableSet_IterGA.p\", \"wb+\"))   \n",
    "\t\t\n",
    "\t\treg = Region(viablePoints, self.model, \"0\")   \n",
    "\t\treg.fitPCA() \n",
    "\t\t\n",
    "\t\tfpca = PCA(n_components=2)  \t\t \t\t\n",
    "\t\tfpca.fit(reg.points)\n",
    "\t\t\t\t\n",
    "\t\tviableSets = list() \n",
    "\t\tviableSets.append(reg)  \t\t  \t\t \n",
    "\t\tconverged = False \t\t\n",
    "\t\titer = 0 \n",
    "\t\t\n",
    "\t\twhile not converged: \n",
    "\t\t\tconverged = True \t\t\t \t\t \t \t\t\t\t\t  \t \n",
    "\t\t\titer += 1 \n",
    "\t\t\tprint(\"Iteration: \" + str(iter))  \t\n",
    "\t\t\tfor set in viableSets:   \t\t\t\t\n",
    "\t\t\t\tset.updateIter() \n",
    "\t\t\t\t#if set not already explored  \n",
    "\t\t\t\tif not set.explored():\n",
    "\t\t\t\t\tsetSize = len(set.points) \n",
    "\t\t\t\t\tprint(\"Label: \" + set.label)   \n",
    "\t\t\t\t\tprint(\"Iter: \" + str(set.iter))  \n",
    "\t\t\t\t\tprint(\"Variance scaling factor: \" + str(set.varScale))    \t\t\t\t\t\t\t\t\n",
    "\t\t\t\t\tconverged = False   \t\t\t\t\t\n",
    "\t\t\t\t\t\t  \n",
    "\t\t\t\t\t#sample with 0 mean and scaled variance of prinicpal components       \n",
    "\t\t\t\t\tcandidateSet = random.multivariate_normal([0]*self.model.nParams, np.diag(set.pca.explained_variance_)*set.varScale, self.nsamples)\t\t\t\t\n",
    "\t\t\t\t\tcandidateSet = set.inverse_transform(candidateSet)      \n",
    "\t\t\t\t\t\t\t\t\n",
    "\t\t\t\t\t#check if parameter values are not out of range  \t\t\n",
    "\t\t\t\t\tinBounds = list() \n",
    "\t\t\t\t\tfor cand in candidateSet: \t\t\t\t\n",
    "\t\t\t\t\t\tif not self.checkOutAllBounds(cand): \n",
    "\t\t\t\t\t\t\tinBounds.append(cand)  \n",
    "\t\t\t\t\tinBounds = np.array(inBounds)   \t\t\n",
    "\t\t\t\t\tcandidateSet = inBounds   \n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\tX = fpca.transform(set.points) \n",
    "\t\t\t\t\ttry:\n",
    "\t\t\t\t\t\tY = fpca.transform(candidateSet) \n",
    "\t\t\t\t\texcept ValueError:\n",
    "\t\t\t\t\t\tcontinue \t \t\t\t\t\n",
    "\t\t\t\t\tfig = plt.figure(iter)  \n",
    "\t\t\t\t\tplt.clf()          \n",
    "\t\t\t\t\tplt.scatter(Y[:, 0], Y[:, 1], c=\"red\", alpha=0.1, edgecolor='k', rasterized=True, label = \"Candidate\")  \n",
    "\t\t\t\t\tplt.scatter(X[:, 0], X[:, 1], c=\"cornflowerblue\", alpha=0.8, edgecolor='k', rasterized=True, label = \"Viable\") \n",
    "\n",
    "\t\t\t\t\tplt.xlabel('PC 1') \n",
    "\t\t\t\t\tplt.ylabel('PC 2')  \n",
    "\t\t\t\t\tplt.title(\"Iteration\"+str(set.iter))  \n",
    "\t\t\t\t\tplt.legend()\n",
    "\t\t\t\t\tplt.close(fig)\n",
    "\t\t\t\t\tplt.savefig(\"./PDFs/\" + filename + \"Set\" + set.label + \"Iter\" + str(set.iter) + \".pdf\")        \t \n",
    "\t\t\t\t\t#identify viable points  \n",
    "\t\t\t\t\tviablePoints = np.array(self.getViablePoints(candidateSet)) \n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\t#if viable set is smaller than number of parameters do not accept it\n",
    "\t\t\t\t\tprint(\"Number of viable points: \" + str(len(viablePoints)))   \n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\tif len(viablePoints) <= setSize/10:   \t\t\t\t\t\t \n",
    "\t\t\t\t\t\t#cluster if not enough points obtained with sampling    \n",
    "\t\t\t\t\t\tprint(\"Clustering, insufficient number of points\")   \n",
    "\t\t\t\t\t\tset.terminated = True      \n",
    "\t\t\t\t\t\tset.cluster = True           \n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tpickle.dump(candidateSet, open(\"./CandidateSets/\" + filename + \"_Region\" + str(set.label) + \"CandidateSet_Iter\" + str(set.iter) +  \".p\", \"wb+\"))     \n",
    "\t\t\t\t\t\tpickle.dump(viablePoints, open(viablesets_filename + \"_Region\" + str(set.label) + \"ViableSet_Iter\" + str(set.iter) + \".p\", \"wb+\"))  \t\t\t\t\t\t\n",
    "\t\t\t\t\t\tset.points = viablePoints           \n",
    "\t\t\t\t\t\tset.fitPCA()     \t \t\t\t\n",
    "\t\t\t\t#if set not already terminated, terminate it and cluster   \n",
    "\t\t\t\telif not set.terminated:    \n",
    "\t\t\t\t\tset.terminated = True       \n",
    "\t\t\t\t\tset.cluster = True         \t\t\t\t\t\n",
    "\t\t\t\t\t\t\n",
    "\t\t\t#clustering, check for new clusters        \t            \n",
    "\t\t\tnewViableSets = list()   \n",
    "\t\t\tfor set in viableSets: \n",
    "\t\t\t\tif set.cluster and (maxDepth == 0 or set.depth < maxDepth):   \n",
    "\t\t\t\t\tset.cluster = False    \n",
    "\t\t\t\t\tsetLabel = set.label    \n",
    "\t\t\t\t\tsetDepth = set.depth      \n",
    "\t\t\t\t\t#determine the optimal number of clusters\n",
    "\t\t\t\t\tprint(\"Clustering set\" + set.label)      \n",
    "\t\t\t\t\tk = self.gapStatistic(set)    \n",
    "\t\t\t\t\tif k > 1:     \n",
    "\t\t\t\t\t\t#cluster and divide sets based on clustering \n",
    "\t\t\t\t\t\t#update the list of sets \n",
    "\t\t\t\t\t\tconverged = False   \n",
    "\t\t\t\t\t\tkmeans = KMeans(n_clusters=k)  \n",
    "\t\t\t\t\t\tlabels = kmeans.fit_predict(set.points)   \n",
    "\t\t\t\t\t\t# centroids = kmeans.cluster_centers_      \n",
    "\t\t\t\t\t\tfor i in range(k): \n",
    "\t\t\t\t\t\t\tind = np.where(labels == i)[0]  \n",
    "\t\t\t\t\t\t\tpoints = set.points[ind]\n",
    "\t\t\t\t\t\t\treg = Region(points, self.model, setLabel + str(i), depth=setDepth+1)         \n",
    "\t\t\t\t\t\t\treg.fitPCA()\n",
    "\t\t\t\t\t\t\tnewViableSets.append(reg)       \t\t\t\t\t\t \t\t\t\n",
    "\t\t\t#end of clustering\t\t\t\t\t \n",
    "\t\t\tviableSets.extend(newViableSets)     \n",
    "\t\t#end of while loop  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ka_min, ka_max = 0., 100.\n",
    "kb_min, kb_max = 0., 500.\n",
    "kcat_min, kcat_max = 0., 500.\n",
    "\n",
    "\n",
    "\n",
    "param_values = {\n",
    "            \"ka1\": {\"min\": ka_min, \"max\": ka_max},  \n",
    "            \"kb1\": {\"min\": kb_min, \"max\": kb_max},             \t\t\t\t        \n",
    "            \"kcat1\": {\"min\": kcat_min, \"max\": kcat_max},         \n",
    "            \"ka2\": {\"min\": ka_min, \"max\": ka_max},         \n",
    "            \"kb2\": {\"min\": kb_min, \"max\": kb_max}, \n",
    "            \"ka3\": {\"min\": ka_min, \"max\":ka_max}, \n",
    "            \"kb3\": {\"min\": kb_min, \"max\":kb_max},\n",
    "            \"ka4\": {\"min\": ka_min, \"max\":ka_max},\n",
    "            \"kb4\": {\"min\": kb_min, \"max\": kb_max},  \n",
    "            \"ka7\": {\"min\": ka_min, \"max\": ka_max}, \n",
    "            \"kb7\": {\"min\": kb_min, \"max\": kb_max}, \n",
    "            \"kcat7\": {\"min\": kcat_min, \"max\": kcat_max},\n",
    "            \"ka8\": {\"min\": ka_min, \"max\": ka_max},\n",
    "            \"kb8\": {\"min\": kb_min, \"max\": kb_max},\n",
    "            \"ka1m\": {\"min\": ka_min, \"max\": ka_max},\n",
    "            \"kb1m\": {\"min\": kb_min, \"max\": kb_max},\n",
    "            # \"ka2m\": {\"min\": ka_min, \"max\": ka_max},\n",
    "            # \"kb2m\": {\"min\": kb_min, \"max\": kb_max},\n",
    "            # \"ka3m\": {\"min\": ka_min, \"max\": ka_max},\n",
    "            # \"kb3m\": {\"min\": kb_min, \"max\": kb_max},\n",
    "            \"ka4m\": {\"min\": ka_min, \"max\": ka_max},\n",
    "            \"kb4m\": {\"min\": kb_min, \"max\": kb_max},\n",
    "            \"ka5m\": {\"min\": ka_min, \"max\": ka_max},\n",
    "            \"kb5m\": {\"min\": kb_min, \"max\": kb_max},\n",
    "            \"ka6m\": {\"min\": ka_min, \"max\": ka_max},\n",
    "            \"kb6m\": {\"min\": kb_min, \"max\": kb_max},\n",
    "            \"ka7m\": {\"min\": ka_min, \"max\": ka_max},\n",
    "            \"kb7m\": {\"min\": kb_min, \"max\": kb_max},\n",
    "            \"ka8m\": {\"min\": ka_min, \"max\": ka_max},\n",
    "            \"kb8m\": {\"min\": kb_min, \"max\": kb_max},\n",
    "            \"ka9m\": {\"min\": ka_min, \"max\": ka_max},\n",
    "            \"kb9m\": {\"min\": kb_min, \"max\": kb_max},\n",
    "            \"ka10m\": {\"min\": ka_min, \"max\": ka_max},\n",
    "            \"kb10m\": {\"min\": kb_min, \"max\": kb_max},\n",
    "            \"ka11m\": {\"min\": ka_min, \"max\": ka_max},\n",
    "            \"kb11m\": {\"min\": kb_min, \"max\": kb_max},\n",
    "            \"ka12m\": {\"min\": ka_min, \"max\": ka_max},\n",
    "            \"kb12m\": {\"min\": kb_min, \"max\": kb_max},\n",
    "            \"ka13m\": {\"min\": ka_min, \"max\": ka_max},\n",
    "            \"kb13m\": {\"min\": kb_min, \"max\": kb_max},\n",
    "            \"ka14m\": {\"min\": ka_min, \"max\": ka_max},\n",
    "            \"kb14m\": {\"min\": kb_min, \"max\": kb_max},\n",
    "            \"VA\": {\"min\": 0.5, \"max\": 1.5}\n",
    "            #\"sigma\": {\"min\": 0.001, \"max\": 0.001}, \n",
    "            # \"L\": {\"min\": 0., \"max\": 15.},  #max 20\n",
    "            # \"Lp\": {\"min\": 0., \"max\": 15.}, \n",
    "            # \"K\": {\"min\": 0., \"max\": 5.}, #min 0.01 max 0.1\n",
    "            # \"P\": {\"min\": 0., \"max\": 5.}, #min 0.01 max 0.1\n",
    "            # \"LK\": {\"min\": 0.0, \"max\": 0.}, \n",
    "            # \"A\": {\"min\": 0., \"max\": 10.}, # max 10\n",
    "            # \"LpA\": {\"min\": 0.0, \"max\": 10.},\n",
    "            # \"LpAK\": {\"min\": 0.0, \"max\": 10.}, \n",
    "            # \"LpAP\": {\"min\": 0.0, \"max\": 10.}, \t\n",
    "            # \"LpAPLp\": {\"min\": 0.0, \"max\": 10.},\n",
    "            # \"LpAKL\": {\"min\": 0.0, \"max\": 10.},\n",
    "            # \"LpP\": {\"min\": 0.0, \"max\": 10.},\n",
    "            }   \t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varnames = [\"L\",\"Lp\",\"K\",\"P\",\"LK\",\"A\",\"LpA\",\"LpAK\",\"LpAP\",\"LpAPLp\",\"LpAKL\",\"LpP\",\"T\",\"X\",\"B\",\"C\",\"D\",\"XB\",\"XC\",\"XD\",\"XBC\",\"XXBC\",\"XBD\",\"XXBD\",\"XCD\",\"XXCD\",\"XBCD\",\"XXBCD\",\"XXXBCD\"]\n",
    "initial_populations = np.append(np.array([0,3,0.2,0.3,0,3,0,0,0,0,0,0,2,1]),(np.zeros((29-14))))\n",
    "\n",
    "initdict = {k:v for k,v in zip(varnames,initial_populations)}\n",
    "initdict['B'] = 0.5\n",
    "initdict['C'] = 0.5\n",
    "initdict['D'] = 0.5\n",
    "initdict['Lp'] = 3.\n",
    "initdict['A'] = 0.9\n",
    "initdict['T'] = 0.3\n",
    "initvals = np.array(list(initdict.values()))\n",
    "initdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename =  os.path.join(\".\", \"CoupledTrimer2\")  \n",
    "print(filename)  \n",
    "model = Oscillator(param_values, np.array([k for k in param_values.keys()]), initvals, mode=1)  #[0,3,0.2,0.3,0,0.9,0,0,0,0,0,0]\n",
    "solver = Solver(model, name = 'CoupledTrimer2')         \n",
    "solver.run(filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mTraceback (most recent call last):\n",
      "\u001b[1;31m  File \"/Users/jonathanfischer/.vscode/extensions/ms-toolsai.jupyter-2022.11.1003412109/pythonFiles/vscode_datascience_helpers/jupyter_daemon.py\", line 158, in _start_notebook\n",
      "\u001b[1;31m    from notebook import notebookapp as app\n",
      "\u001b[1;31m  File \"/Users/jonathanfischer/miniforge3/envs/m1/lib/python3.9/site-packages/notebook/notebookapp.py\", line 59, in <module>\n",
      "\u001b[1;31m    from tornado import httpserver\n",
      "\u001b[1;31m  File \"/Users/jonathanfischer/miniforge3/envs/m1/lib/python3.9/site-packages/tornado/httpserver.py\", line 29, in <module>\n",
      "\u001b[1;31m    import ssl\n",
      "\u001b[1;31m  File \"/Users/jonathanfischer/miniforge3/envs/m1/lib/python3.9/ssl.py\", line 99, in <module>\n",
      "\u001b[1;31m    import _ssl             # if we can't import it, let the error propagate\n",
      "\u001b[1;31mImportError: dlopen(/Users/jonathanfischer/miniforge3/envs/m1/lib/python3.9/lib-dynload/_ssl.cpython-39-darwin.so, 0x0002): Library not loaded: @rpath/libssl.1.1.dylib\n",
      "\u001b[1;31m  Referenced from: <AFC2AED8-3B6E-30C6-8138-6BB9C183B98B> /Users/jonathanfischer/miniforge3/envs/m1/lib/python3.9/lib-dynload/_ssl.cpython-39-darwin.so\n",
      "\u001b[1;31m  Reason: tried: '/Users/jonathanfischer/miniforge3/envs/m1/lib/python3.9/lib-dynload/../../libssl.1.1.dylib' (mach-o file, but is an incompatible architecture (have 'x86_64', need 'arm64')), '/Users/jonathanfischer/miniforge3/envs/m1/lib/python3.9/lib-dynload/../../libssl.1.1.dylib' (mach-o file, but is an incompatible architecture (have 'x86_64', need 'arm64')), '/Users/jonathanfischer/miniforge3/envs/m1/bin/../lib/libssl.1.1.dylib' (mach-o file, but is an incompatible architecture (have 'x86_64', need 'arm64')), '/Users/jonathanfischer/miniforge3/envs/m1/bin/../lib/libssl.1.1.dylib' (mach-o file, but is an incompatible architecture (have 'x86_64', need 'arm64')), '/System/Volumes/Preboot/Cryptexes/OS@rpath/libssl.1.1.dylib' (no such file), '/Users/jonathanfischer/miniforge3/envs/m1/lib/python3.9/lib-dynload/../../libssl.1.1.dylib' (mach-o file, but is an incompatible architecture (have 'x86_64', need 'arm64')), '/Users/jonathanfischer/miniforge3/envs/m1/lib/python3.9/lib-dynload/../../libssl.1.1.dylib' (mach-o file, but is an incompatible architecture (have 'x86_64', need 'arm64')), '/Users/jonathanfischer/miniforge3/envs/m1/bin/../lib/libssl.1.1.dylib' (mach-o file, but is an incompatible architecture (have 'x86_64', need 'arm64')), '/Users/jonathanfischer/miniforge3/envs/m1/bin/../lib/libssl.1.1.dylib' (mach-o file, but is an incompatible architecture (have 'x86_64', need 'arm64')), '/usr/local/lib/libssl.1.1.dylib' (no such file), '/usr/lib/libssl.1.1.dylib' (no such file, not in dyld cache)\n",
      "\u001b[1;31m\n",
      "\u001b[1;31mDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31m\n",
      "\u001b[1;31mTraceback (most recent call last):\n",
      "\u001b[1;31m  File \"/Users/jonathanfischer/.vscode/extensions/ms-toolsai.jupyter-2022.11.1003412109/pythonFiles/vscode_datascience_helpers/daemon/daemon_python.py\", line 54, in _decorator\n",
      "\u001b[1;31m    return func(self, *args, **kwargs)\n",
      "\u001b[1;31m  File \"/Users/jonathanfischer/.vscode/extensions/ms-toolsai.jupyter-2022.11.1003412109/pythonFiles/vscode_datascience_helpers/jupyter_daemon.py\", line 111, in m_exec_module_observable\n",
      "\u001b[1;31m    self._start_notebook(args, cwd, env)\n",
      "\u001b[1;31m  File \"/Users/jonathanfischer/.vscode/extensions/ms-toolsai.jupyter-2022.11.1003412109/pythonFiles/vscode_datascience_helpers/jupyter_daemon.py\", line 160, in _start_notebook\n",
      "\u001b[1;31m    from notebook import app as app\n",
      "\u001b[1;31mImportError: cannot import name 'app' from 'notebook' (/Users/jonathanfischer/miniforge3/envs/m1/lib/python3.9/site-packages/notebook/__init__.py)\n",
      "\u001b[1;31m\n",
      "\u001b[1;31mFailed to run jupyter as observable with args notebook --no-browser --notebook-dir=\"/Users/jonathanfischer/Desktop/Modeling the Living Cell/FinalProject\" --config=/var/folders/p7/6p67sy_d4c9b31d7spz9z9kw0000gn/T/9917c697-9c6e-48b4-8339-d7dd75a0bb93/jupyter_notebook_config.py --NotebookApp.iopub_data_rate_limit=10000000000.0. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# %matplotlib ipympl \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "\n",
    "# Set up the grid and initial concentrations\n",
    "N = 100\n",
    "grid = np.zeros((N, N))\n",
    "grid[N//2, N//2] = 1\n",
    "\n",
    "# Define the reaction-diffusion equations\n",
    "# (these are the classic Gray-Scott equations)\n",
    "dA = 0.1\n",
    "dB = 0.05\n",
    "f = 0.05\n",
    "k = 0.062\n",
    "\n",
    "def update(frame):\n",
    "    global grid\n",
    "\n",
    "    # Compute the new concentrations using the reaction-diffusion equations\n",
    "    new_grid = np.zeros_like(grid)\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            a = grid[i, j]\n",
    "            b = 1 - a\n",
    "            laplacian_a = (\n",
    "                grid[(i+1)%N, j] + grid[(i-1)%N, j] +\n",
    "                grid[i, (j+1)%N] + grid[i, (j-1)%N]\n",
    "            ) / 4 - a\n",
    "            laplacian_b = (\n",
    "                grid[(i+1)%N, j] + grid[(i-1)%N, j] +\n",
    "                grid[i, (j+1)%N] + grid[i, (j-1)%N]\n",
    "            ) / 4 - b\n",
    "            new_grid[i, j] = (\n",
    "                a +\n",
    "                dA * laplacian_a -\n",
    "                a * b**2 +\n",
    "                f * (1 - a)\n",
    "            )\n",
    "            grid[i, j] = (\n",
    "                b +\n",
    "                dB * laplacian_b +\n",
    "                a * b**2 -\n",
    "                (k + f) * b\n",
    "            )\n",
    "\n",
    "    # Update the plot\n",
    "    im.set_data(grid)\n",
    "    return im\n",
    "\n",
    "# Set up the figure and animation\n",
    "fig = plt.figure()\n",
    "im = plt.imshow(grid, cmap='jet', animated=True)\n",
    "plt.colorbar()\n",
    "ani = animation.FuncAnimation(fig, update, frames=100, interval=100)\n",
    "\n",
    "ani.save('reaction-diffusion.gif', writer='Pillow', fps=30)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing /Users/jonathanfischer/miniforge3/envs/m1/lib/python3.9/site-packages/ipympl/nbextension -> jupyter-matplotlib\n",
      "Making directory: /usr/local/share/jupyter/nbextensions/jupyter-matplotlib/\n",
      "Copying: /Users/jonathanfischer/miniforge3/envs/m1/lib/python3.9/site-packages/ipympl/nbextension/index.js -> /usr/local/share/jupyter/nbextensions/jupyter-matplotlib/index.js\n",
      "Copying: /Users/jonathanfischer/miniforge3/envs/m1/lib/python3.9/site-packages/ipympl/nbextension/index.js.map -> /usr/local/share/jupyter/nbextensions/jupyter-matplotlib/index.js.map\n",
      "Copying: /Users/jonathanfischer/miniforge3/envs/m1/lib/python3.9/site-packages/ipympl/nbextension/index.js.LICENSE.txt -> /usr/local/share/jupyter/nbextensions/jupyter-matplotlib/index.js.LICENSE.txt\n",
      "Copying: /Users/jonathanfischer/miniforge3/envs/m1/lib/python3.9/site-packages/ipympl/nbextension/extension.js -> /usr/local/share/jupyter/nbextensions/jupyter-matplotlib/extension.js\n",
      "- Validating: \u001b[32mOK\u001b[0m\n",
      "\n",
      "    To initialize this nbextension in the browser every time the notebook (or other app) loads:\n",
      "    \n",
      "          jupyter nbextension enable ipympl --py\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "!jupyter nbextension install --py ipympl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mTraceback (most recent call last):\n",
      "\u001b[1;31m  File \"/Users/jonathanfischer/.vscode/extensions/ms-toolsai.jupyter-2022.11.1003412109/pythonFiles/vscode_datascience_helpers/jupyter_daemon.py\", line 158, in _start_notebook\n",
      "\u001b[1;31m    from notebook import notebookapp as app\n",
      "\u001b[1;31m  File \"/Users/jonathanfischer/miniforge3/envs/m1/lib/python3.9/site-packages/notebook/notebookapp.py\", line 59, in <module>\n",
      "\u001b[1;31m    from tornado import httpserver\n",
      "\u001b[1;31m  File \"/Users/jonathanfischer/miniforge3/envs/m1/lib/python3.9/site-packages/tornado/httpserver.py\", line 29, in <module>\n",
      "\u001b[1;31m    import ssl\n",
      "\u001b[1;31m  File \"/Users/jonathanfischer/miniforge3/envs/m1/lib/python3.9/ssl.py\", line 99, in <module>\n",
      "\u001b[1;31m    import _ssl             # if we can't import it, let the error propagate\n",
      "\u001b[1;31mImportError: dlopen(/Users/jonathanfischer/miniforge3/envs/m1/lib/python3.9/lib-dynload/_ssl.cpython-39-darwin.so, 0x0002): Library not loaded: @rpath/libssl.1.1.dylib\n",
      "\u001b[1;31m  Referenced from: <AFC2AED8-3B6E-30C6-8138-6BB9C183B98B> /Users/jonathanfischer/miniforge3/envs/m1/lib/python3.9/lib-dynload/_ssl.cpython-39-darwin.so\n",
      "\u001b[1;31m  Reason: tried: '/Users/jonathanfischer/miniforge3/envs/m1/lib/python3.9/lib-dynload/../../libssl.1.1.dylib' (mach-o file, but is an incompatible architecture (have 'x86_64', need 'arm64')), '/Users/jonathanfischer/miniforge3/envs/m1/lib/python3.9/lib-dynload/../../libssl.1.1.dylib' (mach-o file, but is an incompatible architecture (have 'x86_64', need 'arm64')), '/Users/jonathanfischer/miniforge3/envs/m1/bin/../lib/libssl.1.1.dylib' (mach-o file, but is an incompatible architecture (have 'x86_64', need 'arm64')), '/Users/jonathanfischer/miniforge3/envs/m1/bin/../lib/libssl.1.1.dylib' (mach-o file, but is an incompatible architecture (have 'x86_64', need 'arm64')), '/System/Volumes/Preboot/Cryptexes/OS@rpath/libssl.1.1.dylib' (no such file), '/Users/jonathanfischer/miniforge3/envs/m1/lib/python3.9/lib-dynload/../../libssl.1.1.dylib' (mach-o file, but is an incompatible architecture (have 'x86_64', need 'arm64')), '/Users/jonathanfischer/miniforge3/envs/m1/lib/python3.9/lib-dynload/../../libssl.1.1.dylib' (mach-o file, but is an incompatible architecture (have 'x86_64', need 'arm64')), '/Users/jonathanfischer/miniforge3/envs/m1/bin/../lib/libssl.1.1.dylib' (mach-o file, but is an incompatible architecture (have 'x86_64', need 'arm64')), '/Users/jonathanfischer/miniforge3/envs/m1/bin/../lib/libssl.1.1.dylib' (mach-o file, but is an incompatible architecture (have 'x86_64', need 'arm64')), '/usr/local/lib/libssl.1.1.dylib' (no such file), '/usr/lib/libssl.1.1.dylib' (no such file, not in dyld cache)\n",
      "\u001b[1;31m\n",
      "\u001b[1;31mDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31m\n",
      "\u001b[1;31mTraceback (most recent call last):\n",
      "\u001b[1;31m  File \"/Users/jonathanfischer/.vscode/extensions/ms-toolsai.jupyter-2022.11.1003412109/pythonFiles/vscode_datascience_helpers/daemon/daemon_python.py\", line 54, in _decorator\n",
      "\u001b[1;31m    return func(self, *args, **kwargs)\n",
      "\u001b[1;31m  File \"/Users/jonathanfischer/.vscode/extensions/ms-toolsai.jupyter-2022.11.1003412109/pythonFiles/vscode_datascience_helpers/jupyter_daemon.py\", line 111, in m_exec_module_observable\n",
      "\u001b[1;31m    self._start_notebook(args, cwd, env)\n",
      "\u001b[1;31m  File \"/Users/jonathanfischer/.vscode/extensions/ms-toolsai.jupyter-2022.11.1003412109/pythonFiles/vscode_datascience_helpers/jupyter_daemon.py\", line 160, in _start_notebook\n",
      "\u001b[1;31m    from notebook import app as app\n",
      "\u001b[1;31mImportError: cannot import name 'app' from 'notebook' (/Users/jonathanfischer/miniforge3/envs/m1/lib/python3.9/site-packages/notebook/__init__.py)\n",
      "\u001b[1;31m\n",
      "\u001b[1;31mFailed to run jupyter as observable with args notebook --no-browser --notebook-dir=\"/Users/jonathanfischer/Desktop/Modeling the Living Cell/FinalProject\" --config=/var/folders/p7/6p67sy_d4c9b31d7spz9z9kw0000gn/T/b118c80e-c397-4f69-8d2b-3a488516cf57/jupyter_notebook_config.py --NotebookApp.iopub_data_rate_limit=10000000000.0. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "!jupyter nbextension disable ipympl --py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 | packaged by conda-forge | (main, May 27 2022, 17:00:33) \n[Clang 13.0.1 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "97650612f190689b99c6e021287d2f2e8b9034f26a70891df7accfb106e93556"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
